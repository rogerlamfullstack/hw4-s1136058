{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7e3a0e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Jupyter notebook cell content for COMPAS fairness audit and mitigation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from aif360.datasets import CompasDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = CompasDataset()\n",
    "dataset = dataset.dropna()\n",
    "\n",
    "#  Train/Test split \n",
    "train, test = dataset.split([0.7], shuffle=True)\n",
    "\n",
    "# Build baseline model pipeline \n",
    "X_train = train.features\n",
    "y_train = train.labels.ravel()\n",
    "X_test = test.features\n",
    "y_test = test.labels.ravel()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(solver='liblinear'))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "#  Evaluate fairness (SPD, EOD)\n",
    "test_pred = test.copy()\n",
    "test_pred.labels = y_pred.reshape(-1, 1)\n",
    "\n",
    "metric = ClassificationMetric(\n",
    "    test, test_pred,\n",
    "    unprivileged_groups=[{\"race\": 1}],\n",
    "    privileged_groups=[{\"race\": 0}]\n",
    ")\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Statistical Parity Difference:\", metric.statistical_parity_difference())\n",
    "print(\"Equalized Odds Difference:\", metric.equal_opportunity_difference())\n",
    "\n",
    "# Mitigation using Reweighing \n",
    "RW = Reweighing(unprivileged_groups=[{\"race\": 1}], privileged_groups=[{\"race\": 0}])\n",
    "RW.fit(train)\n",
    "train_transf = RW.transform(train)\n",
    "\n",
    "X_train_rw = train_transf.features\n",
    "y_train_rw = train_transf.labels.ravel()\n",
    "sample_weights = train_transf.instance_weights\n",
    "\n",
    "pipeline.fit(X_train_rw, y_train_rw, clf__sample_weight=sample_weights)\n",
    "y_pred_rw = pipeline.predict(X_test)\n",
    "\n",
    "# Post-mitigation metrics \n",
    "test_pred_rw = test.copy()\n",
    "test_pred_rw.labels = y_pred_rw.reshape(-1, 1)\n",
    "\n",
    "metric_rw = ClassificationMetric(\n",
    "    test, test_pred_rw,\n",
    "    unprivileged_groups=[{\"race\": 1}],\n",
    "    privileged_groups=[{\"race\": 0}]\n",
    ")\n",
    "\n",
    "print(\"Accuracy (Reweighed):\", accuracy_score(y_test, y_pred_rw))\n",
    "print(\"SPD (Reweighed):\", metric_rw.statistical_parity_difference())\n",
    "print(\"EOD (Reweighed):\", metric_rw.equal_opportunity_difference())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
